---
layout: post
title: "7. 시연영상 및 문제점"
description : ""
tag: capstone
---

동영상 수집 및 다운로드, 이미지 분할, Image Caption
---

{% include youtubePlayer.html id="XYXqH3uqZp0" %}
[https://www.youtube.com/watch?v=XYXqH3uqZp0](https://www.youtube.com/watch?v=XYXqH3uqZp0)

문장 입력 및 동영상 출력
---

{% include youtubePlayer.html id="gn1H9k9F7PM" %}
[https://www.youtube.com/watch?v=gn1H9k9F7PM](https://www.youtube.com/watch?v=gn1H9k9F7PM)

문제점
---

지금까지 글을 보셨으면 눈치채셨을 수 있지만, 이 시스템에는 크게 3가지의 문제점이 있습니다.
1. 적절한 이미지가 주어져야 한다.
2. 적절한 이미지가 주어지더라도 im2txt에서 만들어내는 caption는 완전하지 않다.
3. [paraphrase-id-tensorflow](https://github.com/nelson-liu/paraphrase-id-tensorflow) 에서 비교하는 문장과 caption의 언어적인 특성이 다르다.

### 1. 적절한 이미지가 주어져야 한다.

빠르게 움직이는 동영상을 보면 명확한 객체가 있는 사물을 얻어내기 힘들 것 입니다. 그렇기 때문에 동영상에서 이미지를 자르게 되면 적절한 이미지를 얻기 힘들 때도 있습니다.

### 2. im2txt에서 얻는 caption은 완전하지 않다.

word_count.txt 를 보시면 11519의 조각들을 사용합니다. 한정된 조각들로 문장을 만들어 내다보니 어느정도 제한이 있다고 생각합니다.

그리고 아래와 같은 사진을 보시면 때로는 이미지와 다른 의미의 caption을 만들어내기도 합니다.

![im2txt]({{ site.assets | absolute_url }}/capstone/7_im2txt.jpg)

스토리가 있는 여러장의 이미지가 있는 경우 im2txt는 스토리를 반영하지 않습니다. 그렇게 때문에 제한된 정보를 얻는다고 할 수 있습니다.

이에 대한 연구들도 진행이 되고 있는데, 구글에 'Sequence to Sequence', 'Video to Text' 라고 검색해보시면 찾아보실수 있습니다.

{% include youtubePlayer.html id="XTq0huTXj1M" %}
[https://www.youtube.com/watch?v=XTq0huTXj1M](https://www.youtube.com/watch?v=XTq0huTXj1M)

### 3. 문장 비교를 하는 언어적 특징이 다르다.

Caption 되는 문장들은 '~하는 객체' 라는 식으로 명사적인 형태를 갖고 있습니다.
반면 Manhattan LSTM으로 비교하는 문장은 '~합니다' 라는 일상생활에서 쓰이는 문장형태 입니다.

따라서 Caption 되는 명사적 형태의 문장을 실제 서술적인 문장으로 변형되어야 합니다.

결론
---

위와 같은 문제들의 불완정성이 모이면서 실제 저희 시스템의 결과는 출력이 잘 되지는 않습니다.

하지만 핵심 단어로 검색에 이루어지는 기존 검색 엔진은 불편함을 느끼지 않을 수 있지만 언젠가는 더 다양한 검색을 원하는 사용자층이 늘어남에 따라 문장의 이미를 이해하고 결과를 도출해내는 시도는 의미있었다고 생각합니다.
